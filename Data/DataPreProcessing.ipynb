{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data to Estimate the heating energy model\n",
    "\n",
    "* Collecting the hot water data to compute the heating energy output\n",
    "* Input to the model: preheat temp/st pt au 1&2, reheat temp/st pt ahu 1&2, zone temps, outside temp and rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "from pandas import *\n",
    "from matplotlib import *\n",
    "import numpy as np\n",
    "from matplotlib import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting data for hot water energy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data to calculate the energy\n",
    "df3 = df3 = read_excel('TotalEnergy2018.xlsx',sheet_name='Sheet3')\n",
    "#sample type 1 date='11/4/18 1:00:00 AM CDT'\n",
    "#sample type 2 date='11/4/18 2:00:00 AM CST'\n",
    "df3.Time = df3.Time.map(lambda x: x.rsplit(None, 1)[0])#removing time zone information #no axis info since it is a series\n",
    "df3.insert(loc=0, column='Dates', value=to_datetime(df3['Time'],format='%m/%d/%y, %I:%M:%S %p'))\n",
    "\n",
    "#Converting to Central Standard Time\n",
    "CDTStart = 19896\n",
    "CDTEnd = 110113+1#Since indexing ignores last value\n",
    "df3['Dates'].iloc[CDTStart:CDTEnd] = df3['Dates'].iloc[CDTStart:CDTEnd] - DateOffset(hours=1)\n",
    "\n",
    "#Setting Dates as the dataframe index\n",
    "df3.set_index(['Dates'], drop=True, inplace=True)\n",
    "df3.drop('Time',axis=1,inplace=True)#Drop original Time column\n",
    "\n",
    "#Selecting time points only at 5 minute intervals\n",
    "mask = np.logical_and((df3.index.minute % 5) == 0, (df3.index.second) == 0)\n",
    "df3 = df3[mask]\n",
    "\n",
    "#Dropping any row with ill conditioned data like ??? etc\n",
    "for i in df3.columns:\n",
    "    df3 = df3[~df3[i].apply(lambda x: isinstance(x, str))]\n",
    "    \n",
    "#Ensuring objects are all converted to float\n",
    "df3 = df3.astype('float')\n",
    "\n",
    "#Dropiing duplicated time points that may exist in the data\n",
    "df3 = df3[~df3.index.duplicated()]\n",
    "df3.index.is_unique #Statutory Check\n",
    "\n",
    "#Dropping rows with values < 0\n",
    "for i in df3.columns:\n",
    "    df3 = df3[df3[i]>0]\n",
    "    \n",
    "#Dropping any empty row\n",
    "df3.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the enrgy based on the dataframe\n",
    "Used the formula\n",
    "$H = 500*(FlowRate)*(SupplyTemp-ReturnTemp)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HeatEnergy(x):\n",
    "    tempDiff = x['Hot Water Supply Temperature.Hot Water Supply Temperature.Trend - Present Value ()']-x['Hot Water Return Temperature.Hot Water Return Temperature.Trend - Present Value ()']\n",
    "    energy = 500*x['Flow Rate.Trend - Present Value']*tempDiff\n",
    "    return energy\n",
    "\n",
    "df3 = df3[df3['Flow Rate.Trend - Present Value']>0]\n",
    "df3['Heat_energy'] = df3.apply(lambda x: HeatEnergy(x) , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OAT, DAT, DAT_STP for AHU1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the outside air temperature, da temp and st point for ahu 1\n",
    "df2 = read_excel('TotalEnergy2018.xlsx',sheet_name='Sheet2')\n",
    "#sample type 1 date='11/4/18 1:00:00 AM CDT'\n",
    "#sample type 2 date='11/4/18 2:00:00 AM CST'\n",
    "df2.Time = df2.Time.map(lambda x: x.rsplit(None, 1)[0])#removing time zone information #no axis info since it is a series\n",
    "df2.insert(loc=0, column='Dates', value=to_datetime(df2['Time'],format='%m/%d/%y, %I:%M:%S %p'))\n",
    "\n",
    "#Converting to Central Standard Time\n",
    "CDTStart = 19896\n",
    "CDTEnd = 87918+1#Since indexing ignores last value\n",
    "df2['Dates'].iloc[CDTStart:CDTEnd] = df2['Dates'].iloc[CDTStart:CDTEnd] - DateOffset(hours=1)\n",
    "\n",
    "#Setting Dates as the dataframe index\n",
    "df2.set_index(['Dates'], drop=True, inplace=True)\n",
    "df2.drop('Time',axis=1,inplace=True)#Drop original Time column\n",
    "\n",
    "#Selecting time points only at 5 minute intervals\n",
    "mask = np.logical_and((df2.index.minute % 5) == 0, (df2.index.second) == 0)\n",
    "df2 = df2[mask]\n",
    "\n",
    "#Dropping any row with ill conditioned data like ??? etc\n",
    "for i in df2.columns:\n",
    "    df2 = df2[~df2[i].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "#Ensuring objects are all converted to float\n",
    "df2 = df2.astype('float')\n",
    "\n",
    "#Dropiing duplicated time points that may exist in the data\n",
    "df2 = df2[~df2.index.duplicated()]\n",
    "df2.index.is_unique #Statutory Check\n",
    "\n",
    "#Dropping rows with values < 0\n",
    "for i in df2.columns:\n",
    "    df2 = df2[df2[i]>0]\n",
    "\n",
    "#Dropping empty rows\n",
    "df2.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Humidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the different Excel Sheets containing different Data Columns\n",
    "#Reading the Relative humidity data\n",
    "df4 = read_excel('BdxData.xlsx',sheet_name='Sheet1')\n",
    "df4.insert(loc=0, column='Dates', value=to_datetime(df4['Date'],format='%m/%d/%Y %H:%M'))\n",
    "\n",
    "#Setting Dates as the dataframe index\n",
    "df4.set_index(['Dates'], drop=True, inplace=True)\n",
    "df4.drop('Date',axis=1,inplace=True)#Drop original Time column\n",
    "\n",
    "#Dropping any row with ill conditioned data like ??? etc\n",
    "for i in df4.columns:\n",
    "    df4 = df4[~df4[i].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "#Ensuring objects are all converted to float\n",
    "df4 = df4.astype('float')\n",
    "\n",
    "#Dropiing duplicated time points that may exist in the data\n",
    "df4 = df4[~df4.index.duplicated()]\n",
    "df4.index.is_unique #Statutory Check\n",
    "\n",
    "#Dropping empty rows\n",
    "df4.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AHU2 DAT DAT_STP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the different Excel Sheets containing different Data Columns\n",
    "#Reading the AHU 2 dat  and dat st pt\n",
    "df5 = read_excel('BdxData.xlsx',sheet_name='Sheet2')\n",
    "df5.insert(loc=0, column='Dates', value=to_datetime(df5['Date'],format='%m/%d/%Y %H:%M'))\n",
    "\n",
    "#Setting Dates as the dataframe index\n",
    "df5.set_index(['Dates'], drop=True, inplace=True)\n",
    "df5.drop('Date',axis=1,inplace=True)#Drop original Time column\n",
    "\n",
    "#Dropping any row with ill conditioned data like ??? etc\n",
    "for i in df5.columns:\n",
    "    df5 = df5[~df5[i].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "#Ensuring objects are all converted to float\n",
    "df5 = df5.astype('float')\n",
    "\n",
    "#Dropiing duplicated time points that may exist in the data\n",
    "df5 = df5[~df5.index.duplicated()]\n",
    "df5.index.is_unique #Statutory Check\n",
    "\n",
    "#Dropping empty rows\n",
    "df5.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Have to collect preheat for ahus 1 and 2 from metasys\n",
    "* Still need to collect the zone temps\n",
    "* Or we can collect the entire ahu 1&2 preheat, reheat data from metasys in one go\n",
    "* The bdx does not have DA_T data\n",
    "* ALSO HAVE TO CHECKI REMOVE THE SPARSE COLUMNSSO THAT TOO MANY DATA POINTS ARE NOT REMOVED\n",
    "# THE PHT for AHUs 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the different Excel Sheets containing different Data Columns\n",
    "#Reading the AHU 1 and 2 pht temp\n",
    "df6 = read_excel('AHU12_PH_T_Data.xlsx',sheet_name='Sheet1')\n",
    "df6.insert(loc=0, column='Dates', value=to_datetime(df6['Date'],format='%m/%d/%Y %H:%M'))\n",
    "\n",
    "#Setting Dates as the dataframe index\n",
    "df6.set_index(['Dates'], drop=True, inplace=True)\n",
    "df6.drop('Date',axis=1,inplace=True)#Drop original Time column\n",
    "\n",
    "#Dropping any row with ill conditioned data like ??? etc\n",
    "for i in df6.columns:\n",
    "    df6 = df6[~df6[i].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "#Ensuring objects are all converted to float\n",
    "df6 = df6.astype('float')\n",
    "\n",
    "#Dropiing duplicated time points that may exist in the data\n",
    "df6 = df6[~df6.index.duplicated()]\n",
    "df6.index.is_unique #Statutory Check\n",
    "\n",
    "#Dropping empty rows\n",
    "df6.dropna(axis=0,how='any',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the data frames to create input and output(only df3 energy)\n",
    "Next step is to collect the zone data and extend all the data to current time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
